import torch
import os
import json
import folder_paths
import comfy.sd
import comfy.utils
import comfy.lora
from server import PromptServer
from aiohttp import web
import numpy as np
from PIL import Image
import hashlib
import urllib.request
import urllib.error
import urllib.parse
import re
import shutil
import time

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

try:
    from utils import MagicUtils
except ImportError:
    from ..utils import MagicUtils

# =============================================================================
# INT8 LoRA æ”¯æŒ - æ•´åˆçš„ä»£ç ï¼ˆä¸ä¾èµ–å¤–éƒ¨å¯¼å…¥ï¼‰
# =============================================================================

# å°è¯•å¯¼å…¥ LoRAAdapterï¼ˆComfyUI çš„é€‚é…å™¨åŸºç±»ï¼‰
try:
    from comfy.weight_adapter.lora import LoRAAdapter
    _LORA_ADAPTER_AVAILABLE = True
except ImportError:
    _LORA_ADAPTER_AVAILABLE = False

# --- INT8 é‡åŒ–å·¥å…·å‡½æ•° ---

def stochastic_round_int8_delta(x: torch.Tensor, scale, seed: int = 0) -> torch.Tensor:
    """
    ä½¿ç”¨éšæœºèˆå…¥å°† delta å¼ é‡é‡åŒ–ä¸º INT8ã€‚
    ç”¨äº LoRA deltas ä»¥æœ€å°åŒ–é‡åŒ–è¯¯å·®ã€‚
    """
    generator = torch.Generator(device=x.device)
    generator.manual_seed(seed)
    
    # ç¼©æ”¾åˆ° INT8 èŒƒå›´
    if isinstance(scale, torch.Tensor):
        scale_val = scale.item() if scale.numel() == 1 else scale
    else:
        scale_val = float(scale)
    
    x_scaled = x / scale_val
    
    # éšæœºèˆå…¥
    x_floor = torch.floor(x_scaled)
    fraction = x_scaled - x_floor
    
    # åœ¨ç›®æ ‡è®¾å¤‡ä¸Šç›´æ¥åˆ›å»ºéšæœºå€¼
    random_vals = torch.rand(x_scaled.shape, generator=generator, device=x.device, dtype=x_scaled.dtype)
    x_rounded = torch.where(random_vals < fraction, x_floor + 1, x_floor)
    
    return torch.clamp(x_rounded, -128, 127).to(torch.int8)

# --- INT8 LoRA é€‚é…å™¨ ---

if _LORA_ADAPTER_AVAILABLE:
    class INT8LoRAPatchAdapter(LoRAAdapter):
        """
        ä¸“é—¨çš„ LoRA é€‚é…å™¨ï¼Œåœ¨ INT8 ç©ºé—´å†…å°±åœ°è¡¥ä¸ INT8 æƒé‡ã€‚
        """
        def __init__(self, loaded_keys, weights, weight_scale, seed=0):
            super().__init__(loaded_keys, weights)
            self.weight_scale = weight_scale
            self.seed = seed

        def calculate_weight(self, weight, key, strength, strength_model, offset, function, intermediate_dtype=torch.float32, original_weight=None):
            v = self.weights
            up, down, alpha = v[0], v[1], v[2]
            
            rank = down.shape[0] if down.ndim >= 2 else 1
            scale = (alpha / rank) * strength if alpha is not None else strength
            
            device = weight.device
            
            # åœ¨é«˜ç²¾åº¦ GPU ä¸Šè®¡ç®— LoRA Delta
            comp_device = torch.device("cuda") if torch.cuda.is_available() else device
            
            up_f = up.to(comp_device, dtype=intermediate_dtype)
            down_f = down.to(comp_device, dtype=intermediate_dtype)
            
            # å¤„ç†å¯èƒ½çš„ mid weights (LoCon/LoHA)
            if v[3] is not None:
                mid_f = v[3].to(comp_device, dtype=intermediate_dtype)
                lora_diff = torch.mm(up_f.flatten(1), torch.mm(mid_f.flatten(1), down_f.flatten(1))).reshape(weight.shape)
            else:
                lora_diff = torch.mm(up_f.flatten(1), down_f.flatten(1)).reshape(weight.shape)
            
            # åº”ç”¨è¡¥ä¸
            if weight.dtype == torch.int8:
                # --- INT8 ç©ºé—´è¡¥ä¸ ---
                delta_f = lora_diff * scale
                delta_int8 = stochastic_round_int8_delta(delta_f, self.weight_scale, self.seed)
                
                # æ‰§è¡Œæ•´æ•°åŠ æ³•ï¼ˆint32 å®‰å…¨ï¼‰ç„¶åé’³åˆ¶
                res = weight.to(comp_device, torch.int32) + delta_int8.to(comp_device, torch.int32)
                return torch.clamp(res, -128, 127).to(torch.int8).to(device)
            else:
                # å›é€€ï¼šæ ‡å‡†æµ®ç‚¹è¡¥ä¸
                return weight + (lora_diff * scale).to(weight.device, weight.dtype)
else:
    INT8LoRAPatchAdapter = None

# --- åŠ¨æ€ LoRA åŒæ­¥ Hook ---

class DynamicLoRAHook:
    """
    åœ¨ diffusion_model ä¸Šæ³¨å†Œçš„ Hookï¼Œç”¨äºåœ¨æ¯æ¬¡å‰å‘ä¼ æ’­å¼€å§‹æ—¶
    å°†åŠ¨æ€ LoRA å±æ€§ä¸å½“å‰ ModelPatcher ä¸Šä¸‹æ–‡åŒæ­¥ã€‚
    """
    def __init__(self):
        self.current_lora_id = None

    def pre_forward(self, module, input_args, input_kwargs):
        # 1. å°è¯•æŸ¥æ‰¾ transformer_options
        transformer_options = input_kwargs.get("transformer_options", {})
        if not transformer_options:
            # å›é€€ï¼šæŸäº›æ¨¡å‹åœ¨ context ä¸­ä¼ é€’
            context = input_args[2] if len(input_args) > 2 else None
            if isinstance(context, dict) and "transformer_options" in context:
                transformer_options = context["transformer_options"]
        
        dynamic_loras = transformer_options.get("dynamic_loras", [])
        
        # 2. ä¸ºæ­¤ LoRA é›†åˆç”Ÿæˆå”¯ä¸€ ID
        # ä½¿ç”¨ handles/strengths æ£€æµ‹å˜åŒ–
        lora_id = hash(tuple((id(d["patches"]), d["strength"]) for d in dynamic_loras)) if dynamic_loras else None
        
        if lora_id == self.current_lora_id:
            return None  # å·²åŒæ­¥
        
        # 3. åŒæ­¥æ‰€æœ‰çº¿æ€§å±‚
        self.apply_composition(module, dynamic_loras)
        self.current_lora_id = lora_id
        return None

    def apply_composition(self, diffusion_model, dynamic_loras):
        # æŒ‰å±‚é¢„åˆ†ç»„è¡¥ä¸
        layer_patches = {}
        if dynamic_loras:
            for entry in dynamic_loras:
                strength = entry["strength"]
                for key, adapter in entry["patches"].items():
                    if key not in layer_patches:
                        layer_patches[key] = []
                    layer_patches[key].append((adapter, strength))

        # æ›´æ–°æ‰€æœ‰æ¨¡å—
        for name, module in diffusion_model.named_modules():
            # æ£€æŸ¥æ˜¯å¦æ˜¯çº¿æ€§å±‚ï¼ˆéœ€è¦æ”¯æŒ LoRAï¼‰
            if not isinstance(module, torch.nn.Linear):
                continue
            
            # å¦‚æœæ¨¡å—æ²¡æœ‰ lora_A å±æ€§ï¼Œåˆå§‹åŒ–å®ƒï¼ˆç”¨äºåŠ¨æ€æ¨¡å¼ï¼‰
            if not hasattr(module, "lora_A"):
                module.lora_A = None
            if not hasattr(module, "lora_B"):
                module.lora_B = None
            if not hasattr(module, "lora_alpha"):
                module.lora_alpha = None
            
            # æŸ¥æ‰¾æ­¤æ¨¡å—çš„è¡¥ä¸
            # ComfyUI é”®é€šå¸¸æ˜¯ 'diffusion_model.path.to.weight' æˆ– 'path.to.weight'
            possible_keys = [f"diffusion_model.{name}.weight", f"{name}.weight"]
            patches = None
            for pk in possible_keys:
                if pk in layer_patches:
                    patches = layer_patches[pk]
                    break
            
            if not patches:
                module.lora_A = None
                module.lora_B = None
                module.lora_alpha = None
                continue

            # ç»„åˆ
            all_A = []
            all_B = []
            for adapter, strength in patches:
                v = adapter.weights
                up, down, alpha, mid = v[0], v[1], v[2], v[3]
                rank = down.shape[0] if down.ndim >= 2 else 1
                scale = (alpha / rank) * strength if alpha is not None else strength
                
                curr_A = down
                if mid is not None:
                    curr_A = torch.mm(mid.flatten(1), down.flatten(1)).reshape(down.shape)
                
                all_A.append(curr_A * scale)
                all_B.append(up)
            
            if all_A:
                device = getattr(module, "weight", torch.tensor(0)).device
                module.lora_A = torch.cat(all_A, dim=0).to(device)
                module.lora_B = torch.cat(all_B, dim=1).to(device)
                module.lora_alpha = None
            else:
                module.lora_A = None
                module.lora_B = None

    @classmethod
    def register(cls, diffusion_model):
        if not hasattr(diffusion_model, "_dynamic_lora_hook"):
            hook = cls()
            diffusion_model._dynamic_lora_hook = hook
            diffusion_model.register_forward_pre_hook(hook.pre_forward, with_kwargs=True)
        return diffusion_model._dynamic_lora_hook

# INT8 æ”¯æŒå¯ç”¨æ€§æ ‡å¿—
INT8_AVAILABLE = _LORA_ADAPTER_AVAILABLE and INT8LoRAPatchAdapter is not None

class MagicPowerLoraLoader:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "model": ("MODEL",),
                "clip": ("CLIP",),
                "lora_stack": ("STRING", {"default": "[]", "multiline": False}),
            },
            "hidden": {
                "int8_mode": ("STRING", {"default": "none"}),
            }
        }

    RETURN_TYPES = ("MODEL", "CLIP", "IMAGE", "STRING")
    RETURN_NAMES = ("model", "clip", "lora_preview", "tags_output")
    OUTPUT_IS_LIST = (False, False, True, False)  # IMAGEæ˜¯åˆ—è¡¨è¾“å‡ºï¼ˆå›¾ç‰‡ç»„ï¼‰
    FUNCTION = "apply_loras"
    CATEGORY = "âœ¨ Magic Assistant"

    # æ£€æµ‹æ¨¡å‹æ˜¯å¦ä¸º INT8 é‡åŒ–æ¨¡å‹
    @staticmethod
    def is_int8_model(model):
        """æ£€æµ‹æ¨¡å‹æ˜¯å¦ä½¿ç”¨ INT8 é‡åŒ–"""
        try:
            if not hasattr(model, 'model') or not hasattr(model.model, 'diffusion_model'):
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡åŒ–å±‚
            for name, module in model.model.diffusion_model.named_modules():
                if hasattr(module, '_is_quantized') and module._is_quantized:
                    return True
                # æ£€æŸ¥æƒé‡æ˜¯å¦ä¸º INT8
                if hasattr(module, 'weight') and hasattr(module.weight, 'dtype'):
                    if module.weight.dtype == torch.int8:
                        return True
            return False
        except Exception:
            return False

    # ğŸŒŸ æ ¸å¿ƒä¿®å¤ï¼šæ›´å¼ºå¤§çš„å›¾ç‰‡æŸ¥æ‰¾é€»è¾‘ï¼ˆä¼˜å…ˆæŸ¥æ‰¾magicloradateå­ç›®å½•ï¼‰
    @staticmethod
    def get_preview_path(lora_name):
        try:
            lora_path = folder_paths.get_full_path("loras", lora_name)
            if lora_path is None: return None
            
            dirname = os.path.dirname(lora_path)
            filename_no_ext = os.path.splitext(os.path.basename(lora_path))[0]
            base_name = os.path.splitext(lora_path)[0]
            
            # å›¾ç‰‡æ‰©å±•åå€™é€‰åˆ—è¡¨
            candidates = [".png", ".jpg", ".jpeg", ".webp"]
            candidates += [".preview.png", ".preview.jpg", ".cover.png", ".cover.jpg"]
            
            # 1. ä¼˜å…ˆæ£€æŸ¥ magicloradate å­ç›®å½•ï¼ˆå‚è€ƒzmlä»£ç çš„zmlå­ç›®å½•ä¼˜å…ˆé€»è¾‘ï¼‰
            magicloradate_dir = os.path.join(dirname, "magicloradate")
            if os.path.isdir(magicloradate_dir):
                for ext in candidates:
                    sub_path = os.path.join(magicloradate_dir, filename_no_ext + ext)
                    if os.path.exists(sub_path):
                        return sub_path
            
            # 2. å¦‚æœmagicloradateå­ç›®å½•æ²¡æœ‰ï¼Œæ£€æŸ¥åŒå±‚çº§
            for ext in candidates:
                if os.path.exists(base_name + ext):
                    return base_name + ext
                
            return None
        except Exception:
            return None

    def apply_loras(self, model, clip, lora_stack, int8_mode="none"):
        """
        åº”ç”¨ LoRA
        int8_mode: "none" (é»˜è®¤), "stochastic" (é™æ€), "dynamic" (åŠ¨æ€)
        """
        out_model = model
        out_clip = clip
        active_tags = []
        preview_images = []  # æ”¹ä¸ºåˆ—è¡¨ï¼Œæ”¶é›†æ‰€æœ‰é¢„è§ˆå›¾

        try:
            if not isinstance(lora_stack, str) or not lora_stack.strip():
                stack_data = []
            else:
                stack_data = json.loads(lora_stack)
        except:
            stack_data = []

        items_to_process = []
        if isinstance(stack_data, dict):
            if "folders" in stack_data:
                for f in stack_data["folders"]:
                    if f.get("loras"):
                        items_to_process.extend([l for l in f["loras"] if l.get("enabled", True)])
            if "loras" in stack_data:
                items_to_process.extend([l for l in stack_data["loras"] if l.get("enabled", True)])
        elif isinstance(stack_data, list):
            items_to_process = [l for l in stack_data if l.get("enabled", True)]

        # æ£€æµ‹æ˜¯å¦ä¸º INT8 æ¨¡å‹
        is_int8 = self.is_int8_model(out_model)
        
        # å¦‚æœå¯ç”¨ INT8 æ¨¡å¼ä½†æ¨¡å‹ä¸æ˜¯ INT8ï¼Œç»™å‡ºè­¦å‘Š
        if int8_mode != "none" and not is_int8:
            print(f"âš ï¸ [MagicPowerLora] INT8 æ¨¡å¼å·²å¯ç”¨ï¼Œä½†æ¨¡å‹ä¼¼ä¹ä¸æ˜¯ INT8 é‡åŒ–æ¨¡å‹ï¼Œå°†å°è¯•ä½¿ç”¨ INT8 åŠ è½½å™¨")
        
        # å¦‚æœæœªå¯ç”¨ INT8 æ¨¡å¼ä½†æ¨¡å‹æ˜¯ INT8ï¼Œç»™å‡ºæç¤º
        if int8_mode == "none" and is_int8:
            print(f"ğŸ’¡ [MagicPowerLora] æ£€æµ‹åˆ° INT8 æ¨¡å‹ï¼Œå»ºè®®åœ¨è®¾ç½®ä¸­å¯ç”¨ INT8 æ¨¡å¼ä»¥è·å¾—æ›´å¥½çš„å…¼å®¹æ€§")

        print(f"ğŸš€ [MagicPowerLora] Processing {len(items_to_process)} Loras... (Mode: {int8_mode})")

        # æ ¹æ®æ¨¡å¼é€‰æ‹©åŠ è½½æ–¹å¼
        if int8_mode == "stochastic" and INT8_AVAILABLE:
            # é™æ€æ¨¡å¼ï¼ˆStochasticï¼‰- æ•´åˆçš„ INT8 LoRA åŠ è½½é€»è¾‘
            for item in items_to_process:
                lora_name = item.get("name")
                weight = float(item.get("weight", 1.0))
                if not lora_name: continue

                lora_path = folder_paths.get_full_path("loras", lora_name)
                if lora_path is None:
                    print(f"âš ï¸ [MagicPowerLora] Lora not found: {lora_name}")
                    continue

                try:
                    # åŠ è½½ LoRA æ–‡ä»¶
                    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)
                    
                    # å…‹éš† model patcher
                    model_patcher = out_model.clone()
                    
                    # è·å–é”®æ˜ å°„
                    key_map = {}
                    if model_patcher.model.model_type.name != "ModelType.CLIP":
                        key_map = comfy.lora.model_lora_keys_unet(model_patcher.model, key_map)
                    
                    # ä½¿ç”¨ ComfyUI çš„ load_lora å¤„ç†å„ç§ LoRA æ ¼å¼
                    patch_dict = comfy.lora.load_lora(lora, key_map, log_missing=True)
                    
                    # å‡çº§è¡¥ä¸ä»¥æ”¯æŒé«˜ç²¾åº¦ INT8 ç©ºé—´è¡¥ä¸
                    final_patch_dict = {}
                    applied_count = 0
                    seed = 318008  # é»˜è®¤ seed
                    
                    for key, adapter in patch_dict.items():
                        # key å¯ä»¥æ˜¯ "layer.name.weight" æˆ– ("layer.name", (dim, start, size))
                        layer_name = key[0] if isinstance(key, tuple) else key
                        if layer_name.endswith(".weight"):
                            layer_name = layer_name[:-7]
                        
                        # è§£ææ¨¡å—ä»¥æ£€æŸ¥é‡åŒ–çŠ¶æ€å¹¶è·å– scale
                        try:
                            parts = layer_name.split(".")
                            target_module = model_patcher.model.diffusion_model
                            for part in parts[1:] if parts[0] == "diffusion_model" else parts:
                                if part.isdigit():
                                    target_module = target_module[int(part)]
                                else:
                                    target_module = getattr(target_module, part)
                            
                            # å¦‚æœæ¨¡å—å·²é‡åŒ–ï¼Œå‡çº§é€‚é…å™¨åˆ°æˆ‘ä»¬çš„é«˜ç²¾åº¦ç‰ˆæœ¬
                            if hasattr(target_module, '_is_quantized') and target_module._is_quantized:
                                w_scale = target_module.weight_scale
                                if isinstance(w_scale, torch.Tensor):
                                    w_scale = w_scale.item() if w_scale.numel() == 1 else w_scale
                                
                                # åˆ›å»ºä¸“é—¨çš„ INT8 é€‚é…å™¨
                                if INT8LoRAPatchAdapter:
                                    new_adapter = INT8LoRAPatchAdapter(
                                        adapter.loaded_keys, 
                                        adapter.weights, 
                                        w_scale,
                                        seed=seed
                                    )
                                    final_patch_dict[key] = new_adapter
                                    applied_count += 1
                                else:
                                    final_patch_dict[key] = adapter
                            else:
                                final_patch_dict[key] = adapter
                                
                        except (AttributeError, KeyError, IndexError, TypeError):
                            final_patch_dict[key] = adapter
                    
                    # æ·»åŠ è¡¥ä¸åˆ° patcher
                    model_patcher.add_patches(final_patch_dict, weight)
                    out_model = model_patcher
                    
                    print(f"   âœ… Applied (INT8 Stochastic): {lora_name} ({applied_count} quantized layers)")
                except Exception as e:
                    print(f"   âŒ Failed (INT8 Stochastic): {lora_name} -> {e}")
                    # å›é€€åˆ°æ ‡å‡†æ¨¡å¼
                    try:
                        lora = comfy.utils.load_torch_file(lora_path, safe_load=True)
                        out_model, out_clip = comfy.sd.load_lora_for_models(out_model, out_clip, lora, weight, weight)
                        print(f"   âœ… Applied (Fallback): {lora_name}")
                    except Exception as e2:
                        print(f"   âŒ Failed (Fallback): {lora_name} -> {e2}")

                if "tags" in item and item["tags"]:
                    active_tags.append(str(item["tags"]))

                # ä¸ºæ¯ä¸ªloraå°è¯•åŠ è½½é¢„è§ˆå›¾
                img_path = self.get_preview_path(lora_name)
                if img_path:
                    try:
                        i = Image.open(img_path).convert("RGB")
                        i = np.array(i).astype(np.float32) / 255.0
                        preview_tensor = torch.from_numpy(i)[None,]
                        preview_images.append(preview_tensor)
                    except Exception as e:
                        print(f"   âš ï¸ Failed to load preview for {lora_name}: {e}")

        elif int8_mode == "dynamic" and INT8_AVAILABLE:
            # åŠ¨æ€æ¨¡å¼ï¼ˆDynamicï¼‰- æ•´åˆçš„ INT8 åŠ¨æ€ LoRA åŠ è½½é€»è¾‘
            for item in items_to_process:
                lora_name = item.get("name")
                weight = float(item.get("weight", 1.0))
                if not lora_name: continue

                lora_path = folder_paths.get_full_path("loras", lora_name)
                if lora_path is None:
                    print(f"âš ï¸ [MagicPowerLora] Lora not found: {lora_name}")
                    continue

                try:
                    # åŠ è½½ LoRA æ–‡ä»¶
                    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)
                    
                    # å…‹éš† model patcher
                    model_patcher = out_model.clone()
                    
                    # 1. è·å–è¡¥ä¸æ˜ å°„
                    key_map = {}
                    if model_patcher.model.model_type.name != "ModelType.CLIP":
                        key_map = comfy.lora.model_lora_keys_unet(model_patcher.model, key_map)
                    
                    patch_dict = comfy.lora.load_lora(lora, key_map, log_missing=True)
                    
                    # 2. æ³¨å†Œå…¨å±€ Hookï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    DynamicLoRAHook.register(model_patcher.model.diffusion_model)
                    
                    # 3. æ·»åŠ åˆ° transformer_options ä¸­çš„åŠ¨æ€ LoRA åˆ—è¡¨
                    # è¿™ç¡®ä¿ ComfyUI çš„å…‹éš†å¤„ç†æ‰€æœ‰å†…å®¹ï¼Œå¹¶ä¸”æ˜¯éç²˜æ€§çš„
                    if "transformer_options" not in model_patcher.model_options:
                        model_patcher.model_options["transformer_options"] = {}
                    
                    opts = model_patcher.model_options["transformer_options"]
                    if "dynamic_loras" not in opts:
                        opts["dynamic_loras"] = []
                    else:
                        # æµ…æ‹·è´åˆ—è¡¨ä»¥é¿å…ä¿®æ”¹çˆ¶ patcher çš„åˆ—è¡¨
                        opts["dynamic_loras"] = opts["dynamic_loras"].copy()
                    
                    opts["dynamic_loras"].append({
                        "name": lora_name,
                        "strength": weight,
                        "patches": patch_dict
                    })
                    
                    out_model = model_patcher
                    print(f"   âœ… Applied (INT8 Dynamic): {lora_name}")
                except Exception as e:
                    print(f"   âŒ Failed (INT8 Dynamic): {lora_name} -> {e}")
                    # å›é€€åˆ°æ ‡å‡†æ¨¡å¼
                    try:
                        lora = comfy.utils.load_torch_file(lora_path, safe_load=True)
                        out_model, out_clip = comfy.sd.load_lora_for_models(out_model, out_clip, lora, weight, weight)
                        print(f"   âœ… Applied (Fallback): {lora_name}")
                    except Exception as e2:
                        print(f"   âŒ Failed (Fallback): {lora_name} -> {e2}")

                if "tags" in item and item["tags"]:
                    active_tags.append(str(item["tags"]))

                # ä¸ºæ¯ä¸ªloraå°è¯•åŠ è½½é¢„è§ˆå›¾
                img_path = self.get_preview_path(lora_name)
                if img_path:
                    try:
                        i = Image.open(img_path).convert("RGB")
                        i = np.array(i).astype(np.float32) / 255.0
                        preview_tensor = torch.from_numpy(i)[None,]
                        preview_images.append(preview_tensor)
                    except Exception as e:
                        print(f"   âš ï¸ Failed to load preview for {lora_name}: {e}")

        else:
            # æ ‡å‡†æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            for item in items_to_process:
                lora_name = item.get("name")
                weight = float(item.get("weight", 1.0))
                if not lora_name: continue

                lora_path = folder_paths.get_full_path("loras", lora_name)
                if lora_path is None:
                    print(f"âš ï¸ [MagicPowerLora] Lora not found: {lora_name}")
                    continue

                try:
                    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)
                    out_model, out_clip = comfy.sd.load_lora_for_models(out_model, out_clip, lora, weight, weight)
                    print(f"   âœ… Applied: {lora_name}")
                except Exception as e:
                    print(f"   âŒ Failed: {lora_name} -> {e}")

                if "tags" in item and item["tags"]:
                    active_tags.append(str(item["tags"]))

                # ä¸ºæ¯ä¸ªloraå°è¯•åŠ è½½é¢„è§ˆå›¾
                img_path = self.get_preview_path(lora_name)
                if img_path:
                    try:
                        i = Image.open(img_path).convert("RGB")
                        i = np.array(i).astype(np.float32) / 255.0
                        preview_tensor = torch.from_numpy(i)[None,]
                        preview_images.append(preview_tensor)
                    except Exception as e:
                        print(f"   âš ï¸ Failed to load preview for {lora_name}: {e}")

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•é¢„è§ˆå›¾ï¼Œè¿”å›ä¸€ä¸ªå ä½å›¾
        if not preview_images:
            preview_images = [torch.zeros((1, 64, 64, 3), dtype=torch.float32, device="cpu")]

        final_text = ", ".join(active_tags)
        return (out_model, out_clip, preview_images, final_text)

# --- API æ¥å£ ---

@PromptServer.instance.routes.get("/ma/lora/list")
async def get_lora_list(request):
    try:
        lora_names = folder_paths.get_filename_list("loras")
        return web.json_response({"files": lora_names})
    except Exception as e:
        return web.json_response({"files": [], "error": str(e)})

@PromptServer.instance.routes.get("/ma/lora/images")
async def get_lora_images(request):
    """è·å–æ‰€æœ‰LoRAæ–‡ä»¶åŠå…¶å¯¹åº”çš„é¢„è§ˆå›¾çš„æ˜ å°„ï¼ˆä¼˜å…ˆæŸ¥æ‰¾magicloradateå­ç›®å½•ï¼‰"""
    try:
        lora_files = folder_paths.get_filename_list("loras")
        images = {}
        
        for lora_filename in lora_files:  # lora_filename is like "subdir/mylora.safetensors"
            lora_full_path = folder_paths.get_full_path("loras", lora_filename)
            if not lora_full_path:
                continue

            lora_dir = os.path.dirname(lora_full_path)
            lora_basename_no_ext = os.path.splitext(os.path.basename(lora_filename))[0]
            
            # ä¼˜å…ˆåœ¨ magicloradate å­ç›®å½•æŸ¥æ‰¾é¢„è§ˆå›¾ï¼Œè‹¥æ— åˆ™æŸ¥æ‰¾åŒå±‚çº§ï¼ˆmagicloradate > åŒå±‚çº§ï¼‰
            magicloradate_dir = os.path.join(lora_dir, "magicloradate")
            found = False
            
            # å…ˆæ£€æŸ¥magicloradateå­ç›®å½•
            for ext in [".png", ".jpg", ".jpeg", ".webp"]:
                preview_path_magic = os.path.join(magicloradate_dir, f"{lora_basename_no_ext}{ext}")
                if os.path.isfile(preview_path_magic):
                    lora_dir_relative = os.path.dirname(lora_filename)  # e.g. "subdir"
                    preview_basename = os.path.basename(preview_path_magic)  # e.g. "mylora.png"
                    relative_path_for_frontend = os.path.join(lora_dir_relative, preview_basename).replace("\\", "/")
                    images[lora_filename] = relative_path_for_frontend
                    found = True
                    break
            
            # å¦‚æœmagicloradateå­ç›®å½•æ²¡æœ‰æ‰¾åˆ°ï¼Œæ£€æŸ¥åŒå±‚çº§
            if not found:
                for ext in [".png", ".jpg", ".jpeg", ".webp"]:
                    preview_path_same = os.path.join(lora_dir, f"{lora_basename_no_ext}{ext}")
                    if os.path.isfile(preview_path_same):
                        lora_dir_relative = os.path.dirname(lora_filename)  # e.g. "subdir"
                        preview_basename = os.path.basename(preview_path_same)  # e.g. "mylora.png"
                        relative_path_for_frontend = os.path.join(lora_dir_relative, preview_basename).replace("\\", "/")
                        images[lora_filename] = relative_path_for_frontend
                        break
            
        return web.json_response(images)
    except Exception as e:
        print(f"è·å–LoRAå›¾ç‰‡åˆ—è¡¨æ—¶å‡ºé”™: {e}")
        return web.json_response({})

@PromptServer.instance.routes.get("/ma/lora/image")
async def get_lora_image(request):
    try:
        name = request.query.get("name")
        if not name: return web.Response(status=404)
        
        img_path = MagicPowerLoraLoader.get_preview_path(name)
        if img_path and os.path.exists(img_path):
            return web.FileResponse(img_path)
        
        return web.Response(status=404)
    except Exception as e:
        print(f"âŒ Image API Error: {e}")
        return web.Response(status=500)

def get_preset_dir():
    target_dir = os.path.join(MagicUtils.USER_DIR, "lora_presets")
    if not os.path.exists(target_dir): os.makedirs(target_dir, exist_ok=True)
    return target_dir

@PromptServer.instance.routes.post("/ma/lora/save_preset")
async def save_preset(request):
    try:
        data = await request.json()
        preset_name = data.get("name")
        content = data.get("content")
        if not preset_name or not content: return web.json_response({"status": "error"})
        
        file_path = os.path.join(get_preset_dir(), f"{preset_name}.json")
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(content, f, indent=4, ensure_ascii=False)
        return web.json_response({"status": "success"})
    except Exception as e: return web.json_response({"status": "error", "message": str(e)})

@PromptServer.instance.routes.get("/ma/lora/get_presets")
async def get_presets(request):
    try:
        preset_dir = get_preset_dir()
        files = [f for f in os.listdir(preset_dir) if f.endswith(".json")]
        presets = {}
        for f in files:
            try:
                with open(os.path.join(preset_dir, f), 'r', encoding='utf-8') as pf:
                    presets[f.replace(".json", "")] = json.load(pf)
            except: pass
        return web.json_response({"presets": presets})
    except Exception as e: return web.json_response({"presets": {}, "error": str(e)})

@PromptServer.instance.routes.post("/ma/lora/delete_preset")
async def delete_preset(request):
    try:
        data = await request.json()
        preset_name = data.get("name")
        if not preset_name: return web.json_response({"status": "error", "message": "ç¼ºå°‘é¢„è®¾åç§°"})
        
        preset_dir = get_preset_dir()
        file_path = os.path.join(preset_dir, f"{preset_name}.json")
        
        if os.path.exists(file_path):
            os.remove(file_path)
            return web.json_response({"status": "success", "message": f"é¢„è®¾ '{preset_name}' å·²åˆ é™¤"})
        else:
            return web.json_response({"status": "error", "message": "é¢„è®¾æ–‡ä»¶ä¸å­˜åœ¨"})
    except Exception as e: return web.json_response({"status": "error", "message": str(e)})

# --- çˆ¬å–åŠŸèƒ½è¾…åŠ©å‡½æ•° ---

def clean_html(raw_html):
    """æ¸…ç†HTMLæ ‡ç­¾"""
    if not raw_html:
        return ""
    text = re.sub(r'</p>|<br\s*/?>', '\n', raw_html, flags=re.IGNORECASE)
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'\n\s*\n', '\n', text).strip()
    return text

def calculate_sha256(filepath):
    """è®¡ç®—æ–‡ä»¶SHA256å“ˆå¸Œå€¼"""
    sha256 = hashlib.sha256()
    chunk_size = 65536
    with open(filepath, 'rb') as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
            sha256.update(chunk)
    return sha256.hexdigest()

def fetch_civitai_data_by_hash(hash_string, max_retries=3, api_delay=0.5):
    """ä»Civitai APIè·å–æ•°æ®ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
    for attempt in range(max_retries):
        try:
            url = f"https://civitai.com/api/v1/model-versions/by-hash/{hash_string}"
            if attempt > 0:
                time.sleep(api_delay * (2 ** attempt))
            else:
                time.sleep(api_delay)
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            req = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(req, timeout=30) as response:
                if response.status == 200:
                    data = json.loads(response.read().decode('utf-8'))
                    model_url = f"https://civitai.com/api/v1/models/{data['modelId']}"
                    model_req = urllib.request.Request(model_url, headers=headers)
                    with urllib.request.urlopen(model_req, timeout=30) as model_response:
                        if model_response.status == 200:
                            data['model'] = json.loads(model_response.read().decode('utf-8'))
                        else:
                            data['model'] = {}
                    return data
        except urllib.error.HTTPError as e:
            if e.code == 429:
                time.sleep(api_delay * (2 ** attempt))
                continue
            elif e.code == 404:
                return None
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(api_delay * (2 ** attempt))
    return None

def download_file(url, destination_path):
    """ä¸‹è½½æ–‡ä»¶ï¼Œå¦‚æœæ˜¯è§†é¢‘åˆ™æå–ç¬¬ä¸€å¸§"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=60) as response:
            if response.status == 200:
                content_type = response.getheader('Content-Type', '')
                is_video = content_type.startswith('video/') or url.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))
                
                if is_video and CV2_AVAILABLE:
                    video_path = destination_path + ".temp.mp4"
                    with open(video_path, 'wb') as out_file:
                        shutil.copyfileobj(response, out_file)
                    
                    cap = cv2.VideoCapture(video_path)
                    if cap.isOpened():
                        ret, frame = cap.read()
                        if ret:
                            img_ext = os.path.splitext(destination_path)[1].lower()
                            if img_ext not in ['.png', '.jpg', '.jpeg', '.webp']:
                                destination_path = os.path.splitext(destination_path)[0] + '.jpg'
                            cv2.imwrite(destination_path, frame)
                            cap.release()
                            try:
                                os.remove(video_path)
                            except:
                                pass
                            return True
                        cap.release()
                    try:
                        os.remove(video_path)
                    except:
                        pass
                    return False
                else:
                    with open(destination_path, 'wb') as out_file:
                        shutil.copyfileobj(response, out_file)
                    return True
    except Exception as e:
        print(f"ä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™ {url}: {e}")
    return False

def extract_lora_weight_from_civitai_data(civitai_data, lora_filename):
    """ä»Civitaiæ•°æ®ä¸­æå–LoRAçš„æ¨èæƒé‡å€¼"""
    try:
        lora_basename = os.path.splitext(lora_filename)[0].lower()
        images = civitai_data.get('images', [])
        for image in images:
            meta = image.get('meta', {})
            resources = meta.get('resources', [])
            for resource in resources:
                resource_name = resource.get('name', '').lower()
                resource_weight = resource.get('weight')
                if (resource_name and resource_weight is not None and 
                    (lora_basename in resource_name or resource_name in lora_basename)):
                    return float(resource_weight)
        return None
    except Exception as e:
        print(f"æå–æƒé‡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        return None

@PromptServer.instance.routes.post("/ma/lora/fetch_metadata")
async def fetch_metadata(request):
    """çˆ¬å–LoRAå…ƒæ•°æ®"""
    try:
        data = await request.json()
        lora_name = data.get("lora_name")
        options = data.get("options", {})
        save_path_mode = data.get("save_path_mode", "same_dir")  # "same_dir" or "subfolder"
        
        if not lora_name:
            return web.json_response({"status": "error", "message": "ç¼ºå°‘lora_nameå‚æ•°"}, status=400)
        
        download_txt = options.get("download_txt", True)
        download_json = options.get("download_json", True)
        download_image = options.get("download_image", True)
        download_log = options.get("download_log", True)
        
        lora_path = folder_paths.get_full_path("loras", lora_name)
        if not lora_path or not os.path.exists(lora_path):
            return web.json_response({"status": "error", "message": f"LoRAæ–‡ä»¶æœªæ‰¾åˆ°: {lora_name}"}, status=404)
        
        lora_dir = os.path.dirname(lora_path)
        lora_basename = os.path.splitext(os.path.basename(lora_path))[0]
        
        # ç¡®å®šä¿å­˜ç›®å½•
        if save_path_mode == "subfolder":
            save_dir = os.path.join(lora_dir, "magicloradate")
            os.makedirs(save_dir, exist_ok=True)
        else:
            save_dir = lora_dir
        
        # è®¡ç®—å“ˆå¸Œå¹¶è·å–Civitaiæ•°æ®
        file_hash = calculate_sha256(lora_path)
        civitai_data = fetch_civitai_data_by_hash(file_hash)
        
        result = {
            "status": "success",
            "message": [],
            "data": {
                "triggerWords": "",
                "jsonInfo": "",
                "logInfo": ""
            }
        }
        
        if not civitai_data:
            result["message"].append("æ— æ³•ä»Civitaiè·å–æ­¤LoRAçš„ä¿¡æ¯ï¼ˆå¯èƒ½æœªä¸Šä¼ æˆ–å“ˆå¸Œä¸åŒ¹é…ï¼‰")
            return web.json_response(result)
        
        model_name = civitai_data.get('model', {}).get('name', 'Unknown')
        result["message"].append(f"å·²ä»Civitaiè·å–åˆ° '{model_name}' çš„ä¿¡æ¯")
        
        # ä¿å­˜è§¦å‘è¯æ–‡ä»¶
        if download_txt and civitai_data.get('trainedWords'):
            words_content = ", ".join(civitai_data['trainedWords'])
            txt_path = os.path.join(save_dir, f"{lora_basename}.txt")
            try:
                with open(txt_path, 'w', encoding='utf-8') as f:
                    f.write(words_content)
                result["data"]["triggerWords"] = words_content
                result["message"].append("è§¦å‘è¯å·²ä¿å­˜")
            except Exception as e:
                result["message"].append(f"è§¦å‘è¯ä¿å­˜å¤±è´¥: {e}")
        
        # ä¿å­˜ä»‹ç»ä¿¡æ¯ï¼ˆJSONæ ¼å¼ï¼‰
        if download_json:
            raw_model_desc = civitai_data.get('model', {}).get('description', '')
            raw_version_desc = civitai_data.get('description', '')
            model_desc = clean_html(raw_model_desc)
            version_desc = clean_html(raw_version_desc)
            base_model = civitai_data.get('baseModel', 'N/A')
            model_id = civitai_data.get('modelId')
            version_id = civitai_data.get('id')
            civitai_link = f"https://civitai.com/models/{model_id}?modelVersionId={version_id}" if model_id and version_id else "é“¾æ¥ä¸å¯ç”¨"
            
            json_content = (
                f"--- åŸºç¡€ä¿¡æ¯ ---\n"
                f"åŸºç¡€æ¨¡å‹: {base_model}\n"
                f"Cç«™é“¾æ¥: {civitai_link}\n\n"
                f"--- æ¨¡å‹ä»‹ç» ---\n\n{model_desc if model_desc else 'æ— æ¨¡å‹ä»‹ç»ã€‚'}\n\n"
                f"--- ç‰ˆæœ¬ä¿¡æ¯ ---\n\n{version_desc if version_desc else 'æ— ç‰ˆæœ¬ä¿¡æ¯ã€‚'}\n"
            )
            json_path = os.path.join(save_dir, f"{lora_basename}.json")
            try:
                with open(json_path, 'w', encoding='utf-8') as f:
                    f.write(json_content)
                result["data"]["jsonInfo"] = json_content
                result["message"].append("ä»‹ç»ä¿¡æ¯å·²ä¿å­˜")
            except Exception as e:
                result["message"].append(f"ä»‹ç»ä¿¡æ¯ä¿å­˜å¤±è´¥: {e}")
        
        # ä¿å­˜é¢„è§ˆå›¾åƒ
        if download_image and civitai_data.get('images'):
            first_image = civitai_data['images'][0]
            img_url = first_image.get('url')
            if img_url:
                img_ext = os.path.splitext(urllib.parse.urlparse(img_url).path)[1]
                if not img_ext or img_ext.lower() not in ['.png', '.jpg', '.jpeg', '.webp']:
                    img_ext = '.jpg'
                img_path = os.path.join(save_dir, f"{lora_basename}{img_ext}")
                if download_file(img_url, img_path):
                    result["message"].append("é¢„è§ˆå›¾åƒå·²ä¿å­˜")
                else:
                    result["message"].append("é¢„è§ˆå›¾åƒä¿å­˜å¤±è´¥")
        
        # ä¿å­˜é»˜è®¤æƒé‡åˆ°.logæ–‡ä»¶
        if download_log:
            preferred_weight = extract_lora_weight_from_civitai_data(civitai_data, os.path.basename(lora_path))
            if preferred_weight is not None:
                log_path = os.path.join(save_dir, f"{lora_basename}.log")
                log_content = f'''{{
"description": "",
"sd version": "",
"activation text": "",
"preferred weight": {preferred_weight},
"negative text": "",
"notes": ""
}}'''
                try:
                    with open(log_path, 'w', encoding='utf-8') as f:
                        f.write(log_content)
                    result["data"]["logInfo"] = log_content
                    result["message"].append(f"é»˜è®¤æƒé‡å·²ä¿å­˜: {preferred_weight}")
                except Exception as e:
                    result["message"].append(f"é»˜è®¤æƒé‡ä¿å­˜å¤±è´¥: {e}")
            else:
                result["message"].append("æœªæ‰¾åˆ°åŒ¹é…çš„æƒé‡ä¿¡æ¯")
        
        result["message"] = "\n".join(result["message"])
        return web.json_response(result)
        
    except Exception as e:
        print(f"çˆ¬å–å…ƒæ•°æ®æ—¶å‡ºé”™: {e}")
        return web.json_response({"status": "error", "message": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {e}"}, status=500)

@PromptServer.instance.routes.post("/ma/lora/probe_save_targets")
async def probe_save_targets(request):
    """æ¢æµ‹æŒ‡å®šLoRAçš„ä¿å­˜ä½ç½®å¯ç”¨æ€§ï¼ˆä¼˜å…ˆæ£€æŸ¥magicloradateå­ç›®å½•ï¼‰"""
    try:
        data = await request.json()
        lora_name = data.get("lora_name") or data.get("lora_filename")
        
        if not lora_name:
            return web.json_response({"status": "error", "message": "ç¼ºå°‘lora_nameå‚æ•°"}, status=400)
        
        lora_path = folder_paths.get_full_path("loras", lora_name)
        if not lora_path or not os.path.exists(lora_path):
            return web.json_response({"status": "error", "message": f"LoRAæ–‡ä»¶æœªæ‰¾åˆ°: {lora_name}"}, status=404)
        
        lora_dir = os.path.dirname(lora_path)
        lora_basename = os.path.splitext(os.path.basename(lora_path))[0]
        
        magicloradate_dir = os.path.join(lora_dir, "magicloradate")
        magicloradate_dir_exists = os.path.isdir(magicloradate_dir)
        
        def check_file(path):
            return os.path.exists(path) and os.access(path, os.R_OK)
        
        same_txt = os.path.join(lora_dir, f"{lora_basename}.txt")
        same_json = os.path.join(lora_dir, f"{lora_basename}.json")
        same_log = os.path.join(lora_dir, f"{lora_basename}.log")
        
        magic_txt = os.path.join(magicloradate_dir, f"{lora_basename}.txt")
        magic_json = os.path.join(magicloradate_dir, f"{lora_basename}.json")
        magic_log = os.path.join(magicloradate_dir, f"{lora_basename}.log")
        
        same_files = {
            "txt": check_file(same_txt),
            "json": check_file(same_json),
            "log": check_file(same_log),
        }
        magic_files = {
            "txt": check_file(magic_txt),
            "json": check_file(magic_json),
            "log": check_file(magic_log),
        }
        
        result = {
            "status": "success",
            "magicloradate_dir_exists": magicloradate_dir_exists,
            "magicloradate_files": magic_files,
            "same_files": same_files,
            "magicloradate_has_readable": any(magic_files.values()),
            "same_has_readable": any(same_files.values()),
        }
        
        return web.json_response(result)
        
    except Exception as e:
        print(f"æ¢æµ‹ä¿å­˜ä½ç½®æ—¶å‡ºé”™: {e}")
        return web.json_response({"status": "error", "message": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {e}"}, status=500)

@PromptServer.instance.routes.post("/ma/lora/save_lora_file")
async def save_lora_file(request):
    """ä¿å­˜æŒ‡å®šLoRAæ–‡ä»¶çš„å†…å®¹ï¼ˆæ”¯æŒä¿å­˜åˆ°magicloradateå­ç›®å½•æˆ–åŒå±‚çº§ï¼‰"""
    try:
        data = await request.json()
        lora_name = data.get("lora_name") or data.get("lora_filename")
        file_type = data.get("file_type", "txt")
        content = data.get("content", "")
        target = str(data.get("target", "same")).lower()
        target = "magicloradate" if target == "magicloradate" or target == "subfolder" else "same"
        
        if not lora_name:
            return web.json_response({"status": "error", "message": "ç¼ºå°‘lora_nameå‚æ•°"}, status=400)
        
        lora_path = folder_paths.get_full_path("loras", lora_name)
        if not lora_path or not os.path.exists(lora_path):
            return web.json_response({"status": "error", "message": f"LoRAæ–‡ä»¶æœªæ‰¾åˆ°: {lora_name}"}, status=404)
        
        lora_dir = os.path.dirname(lora_path)
        lora_basename = os.path.splitext(os.path.basename(lora_path))[0]
        
        if file_type == "txt":
            file_ext = ".txt"
        elif file_type == "log":
            file_ext = ".log"
        else:
            file_ext = ".json"
        
        if target == "magicloradate":
            file_path = os.path.join(lora_dir, "magicloradate", f"{lora_basename}{file_ext}")
        else:
            file_path = os.path.join(lora_dir, f"{lora_basename}{file_ext}")
        
        # è‡ªåŠ¨åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return web.json_response({"status": "success", "message": f"{file_type}æ–‡ä»¶ä¿å­˜æˆåŠŸ"})
        
    except Exception as e:
        print(f"ä¿å­˜LoRAæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return web.json_response({"status": "error", "message": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {e}"}, status=500)

@PromptServer.instance.routes.post("/ma/lora/get_lora_file")
async def get_lora_file(request):
    """è·å–æŒ‡å®šLoRAæ–‡ä»¶çš„å†…å®¹ï¼ˆä¼˜å…ˆä»magicloradateå­ç›®å½•è¯»å–ï¼‰"""
    try:
        data = await request.json()
        lora_name = data.get("lora_name") or data.get("lora_filename")
        file_type = data.get("file_type", "txt")
        
        if not lora_name:
            return web.json_response({"status": "error", "message": "ç¼ºå°‘lora_nameå‚æ•°"}, status=400)
        
        lora_path = folder_paths.get_full_path("loras", lora_name)
        if not lora_path or not os.path.exists(lora_path):
            return web.json_response({"status": "error", "message": f"LoRAæ–‡ä»¶æœªæ‰¾åˆ°: {lora_name}"}, status=404)
        
        lora_dir = os.path.dirname(lora_path)
        lora_basename = os.path.splitext(os.path.basename(lora_path))[0]
        
        if file_type == "txt":
            file_ext = ".txt"
        elif file_type == "log":
            file_ext = ".log"
        else:
            file_ext = ".json"
        
        # ä¼˜å…ˆä»magicloradateå­ç›®å½•è¯»å–ï¼Œè‹¥æ— åˆ™ä»åŒå±‚çº§è¯»å–
        magicloradate_dir = os.path.join(lora_dir, "magicloradate")
        file_path_magic = os.path.join(magicloradate_dir, f"{lora_basename}{file_ext}")
        file_path_same = os.path.join(lora_dir, f"{lora_basename}{file_ext}")
        
        target_file = None
        if os.path.exists(file_path_magic):
            target_file = file_path_magic
        elif os.path.exists(file_path_same):
            target_file = file_path_same
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºå†…å®¹
            return web.json_response({"status": "success", "content": ""})
        
        with open(target_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        return web.json_response({"status": "success", "content": content})
        
    except Exception as e:
        print(f"è¯»å–LoRAæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return web.json_response({"status": "error", "message": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {e}"}, status=500)

@PromptServer.instance.routes.post("/ma/lora/delete_lora_complete")
async def delete_lora_complete(request):
    """ä¸€é”®åˆ é™¤LoRAæ–‡ä»¶åŠå…¶æ‰€æœ‰ç›¸å…³æ–‡ä»¶"""
    try:
        data = await request.json()
        lora_name = data.get("lora_name")
        
        if not lora_name:
            return web.json_response({"status": "error", "message": "ç¼ºå°‘lora_nameå‚æ•°"}, status=400)
        
        lora_path = folder_paths.get_full_path("loras", lora_name)
        if not lora_path or not os.path.exists(lora_path):
            return web.json_response({"status": "error", "message": f"LoRAæ–‡ä»¶æœªæ‰¾åˆ°: {lora_name}"}, status=404)
        
        lora_dir = os.path.dirname(lora_path)
        lora_basename = os.path.splitext(os.path.basename(lora_path))[0]
        
        deleted_files = []
        
        # åˆ é™¤ä¸»LoRAæ–‡ä»¶
        try:
            os.remove(lora_path)
            deleted_files.append(os.path.basename(lora_path))
        except Exception as e:
            return web.json_response({"status": "error", "message": f"æ— æ³•åˆ é™¤ä¸»LoRAæ–‡ä»¶: {e}"}, status=500)
        
        # åˆ é™¤åŒç›®å½•ä¸‹çš„ç›¸å…³æ–‡ä»¶
        for ext in ['.txt', '.json', '.log', '.png', '.jpg', '.jpeg', '.webp']:
            file_path = os.path.join(lora_dir, f"{lora_basename}{ext}")
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    deleted_files.append(os.path.basename(file_path))
                except Exception as e:
                    print(f"åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™ {file_path}: {e}")
        
        # åˆ é™¤magicloradateå­æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
        magicloradate_dir = os.path.join(lora_dir, "magicloradate")
        if os.path.exists(magicloradate_dir):
            import glob
            pattern = os.path.join(magicloradate_dir, f"{lora_basename}.*")
            for file_path in glob.glob(pattern):
                try:
                    os.remove(file_path)
                    deleted_files.append(os.path.basename(file_path))
                except Exception as e:
                    print(f"åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™ {file_path}: {e}")
            
            # å¦‚æœmagicloradateç›®å½•ä¸ºç©ºï¼Œåˆ é™¤å®ƒ
            if os.path.exists(magicloradate_dir) and not os.listdir(magicloradate_dir):
                try:
                    os.rmdir(magicloradate_dir)
                except Exception as e:
                    print(f"åˆ é™¤ç©ºç›®å½•æ—¶å‡ºé”™: {e}")
        
        return web.json_response({
            "status": "success",
            "message": f"æˆåŠŸåˆ é™¤ {len(deleted_files)} ä¸ªæ–‡ä»¶",
            "deleted_files": deleted_files
        })
        
    except Exception as e:
        print(f"åˆ é™¤LoRAæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return web.json_response({"status": "error", "message": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {e}"}, status=500)